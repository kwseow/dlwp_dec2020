{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_CNN_Fashion_MNIST.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMyBMLnK9h8X7ss0ZFNjf+j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"27LQQrPoQ9tY","colab_type":"code","colab":{}},"source":["from keras import models\n","from keras import layers\n","from keras.datasets import fashion_mnist\n","from keras.utils import to_categorical\n","from keras import regularizers\n","\n","# Load the MNIST data\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","print('train_images shape:', train_images.shape)\n","print('test_images shape:', test_images.shape)\n","print('train_labels shape:', train_labels.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZhVDrZsRCl-","colab_type":"code","colab":{}},"source":["#Display a sample\n","extract_image = 10\n","digit = train_images[extract_image]\n","label = train_labels[extract_image]\n","print(\"Label =\",label)\n","import matplotlib.pyplot as plt\n","plt.imshow(digit, cmap=plt.cm.binary)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSMbA6y5RCis","colab_type":"code","colab":{}},"source":["# Process the data for the usage of ANN\n","train_images = train_images.reshape((60000, 28, 28, 1)) # Flatten the image\n","train_images = train_images.astype('float32') / 255\n","test_images = test_images.reshape((10000, 28,28,1))\n","test_images = test_images.astype('float32') / 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLsdnk-ERCfT","colab_type":"code","colab":{}},"source":["train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"arfH0_m4RCcQ","colab_type":"code","colab":{}},"source":["# Create the network\n","network = models.Sequential()\n","network.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)))\n","network.add(layers.Flatten())\n","network.add(layers.Dense(10, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IK0n7yM8RCYu","colab_type":"code","colab":{}},"source":["network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","history = network.fit(train_images, train_labels, validation_split=0.2, epochs=5, batch_size=128, verbose=2)\n","\n","test_loss, test_acc = network.evaluate(test_images, test_labels, verbose=2)\n","print('test_acc:', test_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ntXYE7RRCVE","colab_type":"code","colab":{}},"source":["# list all data in history\n","print(history.history.keys())\n","\n","# Plot the Learning curve\n","import matplotlib.pyplot as plt\n","history_dict = history.history\n","acc_values = history_dict['accuracy']\n","val_acc_values = history_dict['val_accuracy']\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","epochs = range(1, len(loss_values) + 1)\n","plt.plot(epochs, loss_values, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n","plt.plot(epochs, acc_values, 'ro', label='Training accuracy')\n","plt.plot(epochs, val_acc_values, 'r', label='Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Acc/Loss')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]}]}