{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6_VGG_TL_POKEMON.ipynb","provenance":[{"file_id":"1WEt3OsW6Iy6B55CBv_HN3xrQmLW_9Qt6","timestamp":1591876612655}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"42Sb7Qw38CQa","colab_type":"text"},"source":["**Mount Google Drive locally**\n","\n","Mount your Google Drive on your runtime using an authorization code\n","\n"]},{"cell_type":"code","metadata":{"id":"pLBEGMA573Mf","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScQB_ikF8F2W","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import numpy as np\n","import keras\n","import numpy as np\n","import random\n","from imutils import paths\n","from keras.preprocessing import image\n","from keras.preprocessing.image import img_to_array\n","from keras.applications import vgg16\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import models\n","from keras import layers\n","\n","dataset_path = \"/content/drive/My Drive/Deep Learning with Python/Day 1/dataset\"\n","IMAGE_DIMS = (224, 224, 3)\n","BS = 32\n","EPOCHS=100\n","print(\"keras version %s\"%keras.__version__)\n","print(\"opencv version %s\"%cv2.__version__)\n","\n","# initialize the data and labels\n","data = []\n","labels = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KH9xdMRa8g7N","colab_type":"code","colab":{}},"source":["# grab the image paths and randomly shuffle them\n","print(\"[INFO] loading images...\")\n","imagePaths = sorted(list(paths.list_images(dataset_path)))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","# loop over the input images\n","for ind, imagePath in enumerate(imagePaths):\n","\t# load the image, pre-process it, and store it in the data list\n","\tprint(ind, imagePath, imagePath.split(os.path.sep)[-2])\n","\timage = cv2.imread(imagePath)\n","\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n","\timage = img_to_array(image)\n","\tdata.append(image)\n"," \n","\t# extract the class label from the image path and update the\n","\t# labels list\n","\tlabel = imagePath.split(os.path.sep)[-2]\n","\tlabels.append(label)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3s_tVNdb9rSq","colab_type":"code","colab":{}},"source":["# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","print(\"[INFO] data matrix: {:.2f}MB\".format(\n","\tdata.nbytes / (1024 * 1000.0)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Os2OmlKz_QdE","colab_type":"code","colab":{}},"source":["# binarize the labels\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ha9Xy3X3_TLm","colab_type":"code","colab":{}},"source":["# partition the data into training and testing splits using 80% of\n","# the data for training and the remaining 20% for testing\n","(trainX, testX, trainY, testY) = train_test_split(data,\n","\tlabels, test_size=0.2, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6vheJesAFwb","colab_type":"code","colab":{}},"source":["# initialize the model\n","print(\"[INFO] compiling model...\")\n","\n","# Load VGG16 model without the top layers\n","base_layers = vgg16.VGG16(include_top=False, input_shape=IMAGE_DIMS)\n","#base_layers = vgg16.VGG16(include_top=False)\n","\n","# Allow fine tuning to go into the convolution layers\n","for layer in base_layers.layers:\n","     layer.trainable = False\n","\n","# Create the network\n","network = models.Sequential(base_layers.layers)\n","network.add(layers.Flatten())\n","network.add(layers.Dense(5, activation='softmax'))\n","\n","network.compile(optimizer='rmsprop',\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","network.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoWahhTOAI0H","colab_type":"code","colab":{}},"source":["history = network.fit(trainX, trainY, epochs=50, batch_size=32, verbose=2)\n","test_loss, test_acc = network.evaluate(testX, testY, verbose=2)\n","print('test_acc:', test_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-xN--aXFBfud","colab_type":"text"},"source":["Load an image for testing"]},{"cell_type":"code","metadata":{"id":"zwgZaZsSAa5U","colab_type":"code","colab":{}},"source":["# load the image\n","# image = cv2.imread(dataset_path + '/mewtwo/00000000.jpg')\n","image = cv2.imread(dataset_path + '/pikachu/00000000.jpg')\n","\n","# pre-process the image for classification\n","image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n","image = image.astype(\"float\") / 255.0\n","image = img_to_array(image)\n","image = np.expand_dims(image, axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvcYNgtkEPlM","colab_type":"code","colab":{}},"source":["# classify the input image\n","print(\"[INFO] classifying image...\")\n","proba = network.predict(image)[0]\n","idx = np.argmax(proba)\n","label = lb.classes_[idx]\n","\n","print(label)"],"execution_count":0,"outputs":[]}]}